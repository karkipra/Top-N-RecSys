{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>Copyright (c) Microsoft Corporation. All rights reserved.</i>\n",
    "\n",
    "<i>Licensed under the MIT License.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-b8e369b130cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommendation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mALS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyspark\\ml\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0mlearning\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \"\"\"\n\u001b[1;32m---> 22\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mEstimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnaryTransformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPipelineModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclustering\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msince\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshared\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minherit_doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\pyspark\\ml\\param\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mabc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mABCMeta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_gateway\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mJavaObject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# set the environment path to find Recommenders\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import time\n",
    "import pyspark\n",
    "from pyspark.ml.recommendation import ALS\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import StringType, FloatType, IntegerType, LongType, ArrayType\n",
    "\n",
    "from reco_utils.dataset import movielens\n",
    "from reco_utils.common.notebook_utils import is_jupyter\n",
    "from reco_utils.dataset.spark_splitters import spark_random_split\n",
    "from reco_utils.evaluation.spark_evaluation import SparkRatingEvaluation, SparkRankingEvaluation\n",
    "from reco_utils.common.spark_utils import start_or_get_spark\n",
    "\n",
    "print(\"System version: {}\".format(sys.version))\n",
    "print(\"Spark version: {}\".format(pyspark.__version__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    }
   ],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Set up Spark context\n",
    "\n",
    "The following settings work well for debugging locally on VM - change when running on a cluster. We set up a giant single executor with many threads and specify memory cap. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following settings work well for debugging locally on VM - change when running on a cluster\n",
    "# set up a giant single executor with many threads and specify memory cap\n",
    "\n",
    "spark = start_or_get_spark(memory=\"16g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Download the Cell Phone dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define custom schema\n",
    "schema = StructType(\n",
    "    (\n",
    "        StructField(\"asin\", StringType()),\n",
    "        StructField(\"overall\", FloatType()),\n",
    "        StructField(\"reviewerID\", StringType()),\n",
    "        StructField(\"reviewText\", StringType()),\n",
    "        StructField(\"summary\", StringType()),\n",
    "        StructField(\"sentiment_summary\", FloatType()),\n",
    "        StructField(\"sentiment_review\", FloatType())\n",
    "    )\n",
    ")\n",
    "\n",
    "# data = movielens.load_spark_df(spark, size=MOVIELENS_DATA_SIZE, schema=schema)\n",
    "data = spark.read.schema(schema).json(\"data/Cell_Phones_and_Accessories_Sentiment.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+--------------------+--------------------+-----------------+----------------+\n",
      "|      asin|overall|    reviewerID|          reviewText|             summary|sentiment_summary|sentiment_review|\n",
      "+----------+-------+--------------+--------------------+--------------------+-----------------+----------------+\n",
      "|098949232X|    5.0|A1GG51FWU0XQYH|If your into spac...|          Five Stars|              0.0|             0.0|\n",
      "|098949232X|    5.0| AVFIDS9RK38E0|   Awesome pictures!|          Five Stars|              0.0|          0.6588|\n",
      "|098949232X|    5.0|A2S4AVR5SJ7KMI|Great wall art an...|          Five Stars|              0.0|          0.7184|\n",
      "|098949232X|    5.0| AEMMMVOR9BFLI|As always, it is ...|I love it. I buy ...|           0.6369|          0.8016|\n",
      "|098949232X|    5.0|A2DZXMBTY7KLYP|This is a fantast...|     Great Calendar.|           0.6249|          0.8689|\n",
      "|098949232X|    5.0| AUD367H6I25FX|It's great, I get...|    Awesome Calendar|           0.6249|          0.6249|\n",
      "|098949232X|    5.0|A3K6KUWAZ6SWHE|2015 will be my 3...|     Great calendar!|           0.6588|          0.8221|\n",
      "|098949232X|    5.0|A1FPEO0ME9G4VY|My son loves this...|          Five Stars|              0.0|          0.6114|\n",
      "|098949232X|    5.0|A20AOY7UXJA710|A great calendar ...|Great Calendar fo...|           0.6249|          0.9186|\n",
      "|098949232X|    5.0|A222LHL23AH0GK|Lots and lots of ...|          Five Stars|              0.0|             0.0|\n",
      "|098949232X|    5.0| AZSP9XAX38DG0|I love all the sp...|I love all the sp...|           0.6369|          0.8555|\n",
      "|098949232X|    5.0|A1N5IO8FW9EE6R|Hung it in a high...|          Five Stars|              0.0|             0.0|\n",
      "|098949232X|    5.0|A1QI7X0NQ1PUHD|This is a must fo...|A must for astron...|           0.5267|          0.8271|\n",
      "|098949232X|    5.0|A3SF5P30FK4Y5Y|Nice printing. Lo...|Great & interesti...|           0.7783|          0.8591|\n",
      "|098949232X|    5.0|A3KZZYLU5VT4VJ|Very nice and del...|Nice wall calenda...|            0.836|          0.7089|\n",
      "|098949232X|    5.0| ALK31UO248EH1|I have been buyin...|It is beautifully...|           0.8519|          0.9169|\n",
      "|098949232X|    5.0| AP5I1RWKMQ6BT|Each page is full...| Visual eye candy...|              0.0|          0.8934|\n",
      "|098949232X|    5.0|A1TKWOUJB8OE8T|One of the cooles...|All the extra coo...|           0.3182|          0.8858|\n",
      "|098949232X|    5.0|A1VKQUQJHJRA3F|Great pictures an...|          Five Stars|              0.0|          0.7906|\n",
      "|098949232X|    5.0| A1399ZMDHQ1YH|This thing is Big...|Not all Who Wande...|          -0.3182|          0.9734|\n",
      "+----------+-------+--------------+--------------------+--------------------+-----------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+--------------+--------------------+----------+-----------------+----------------+------------+-------------+\n",
      "|      asin|overall|    reviewerID|          reviewText|   summary|sentiment_summary|sentiment_review|productIndex|reviewerIndex|\n",
      "+----------+-------+--------------+--------------------+----------+-----------------+----------------+------------+-------------+\n",
      "|098949232X|    5.0|A1GG51FWU0XQYH|If your into spac...|Five Stars|              0.0|             0.0|           1|            1|\n",
      "+----------+-------+--------------+--------------------+----------+-----------------+----------------+------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "#https://stackoverflow.com/questions/48279056/how-to-create-row-index-for-a-spark-dataframe-using-window-partionby\n",
    "w = Window().partitionBy().orderBy(\"asin\")\n",
    "data = data.withColumn('productIndex',F.rank().over(w))\n",
    "\n",
    "w = Window().partitionBy().orderBy(\"reviewerID\")\n",
    "data = data.withColumn('reviewerIndex',F.rank().over(w))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VADER sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "new_data = []\n",
    "with open('data/Cell_Phones_and_Accessories.json') as json_file:\n",
    "    for line in json_file:\n",
    "        new_data.append(json.loads(line))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in new_data[:20000]:\n",
    "    \n",
    "    try:\n",
    "        line['sentiment_review'] = analyser.polarity_scores(line['reviewText'])['compound']\n",
    "    except:\n",
    "        line['sentiment_review'] = 0.0\n",
    "        \n",
    "    try:\n",
    "        line['sentiment_summary'] = analyser.polarity_scores(line['summary'])['compound']\n",
    "    except:\n",
    "        line['sentiment_summary'] = 0.0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'A1GG51FWU0XQYH', 'asin': '098949232X', 'reviewerName': 'Paul Williams', 'reviewText': 'If your into space this is the Calendar for you.', 'summary': 'Five Stars', 'unixReviewTime': 1416355200, 'sentiment_review': 0.0, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'AVFIDS9RK38E0', 'asin': '098949232X', 'reviewerName': 'Sean Powell', 'reviewText': 'Awesome pictures!', 'summary': 'Five Stars', 'unixReviewTime': 1416355200, 'sentiment_review': 0.6588, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'A2S4AVR5SJ7KMI', 'asin': '098949232X', 'reviewerName': 'Tom Davis', 'reviewText': 'Great wall art and information for space exploration minded people.', 'summary': 'Five Stars', 'unixReviewTime': 1416355200, 'sentiment_review': 0.7184, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'AEMMMVOR9BFLI', 'asin': '098949232X', 'reviewerName': 'Kwajmeck', 'reviewText': 'As always, it is a quality calendar full of very interesting space-related photos and information.  I love it.  I buy a new one every year.', 'summary': 'I love it. I buy a new one every year', 'unixReviewTime': 1416355200, 'sentiment_review': 0.8016, 'sentiment_summary': 0.6369}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'A2DZXMBTY7KLYP', 'asin': '098949232X', 'reviewerName': 'ScottG43', 'reviewText': 'This is a fantastic calendar. This is my third year purchasing it. It is sturdy and well put together and has a bunch of awesome information in it.', 'summary': 'Great Calendar.', 'unixReviewTime': 1416355200, 'sentiment_review': 0.8689, 'sentiment_summary': 0.6249}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'AUD367H6I25FX', 'asin': '098949232X', 'reviewerName': 'Michael Lee Warren', 'reviewText': \"It's great, I get it every year.\", 'summary': 'Awesome Calendar', 'unixReviewTime': 1416355200, 'sentiment_review': 0.6249, 'sentiment_summary': 0.6249}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'A3K6KUWAZ6SWHE', 'asin': '098949232X', 'reviewerName': 'Daniel Alexander Poole', 'reviewText': '2015 will be my 3rd year, looking forward to it! I always enjoy flipping toothed next month. The desk calendar is also great.', 'summary': 'Great calendar!', 'unixReviewTime': 1416355200, 'sentiment_review': 0.8221, 'sentiment_summary': 0.6588}, {'overall': 5.0, 'verified': False, 'reviewTime': '11 19, 2014', 'reviewerID': 'A1FPEO0ME9G4VY', 'asin': '098949232X', 'reviewerName': 'B. Willey', 'reviewText': 'My son loves this every year!', 'summary': 'Five Stars', 'unixReviewTime': 1416355200, 'sentiment_review': 0.6114, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 20, 2015', 'reviewerID': 'A20AOY7UXJA710', 'asin': '098949232X', 'reviewerName': 'Michael D', 'reviewText': 'A great calendar for the space or science enthusiast.  Ever month includes lots of wonderful astonomical photographs and interesting information on verious astonomical subjects.', 'summary': 'Great Calendar for Space Fans', 'unixReviewTime': 1424390400, 'sentiment_review': 0.9186, 'sentiment_summary': 0.6249}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 13, 2015', 'reviewerID': 'A222LHL23AH0GK', 'asin': '098949232X', 'reviewerName': 'Nancy', 'reviewText': 'Lots and lots of info', 'summary': 'Five Stars', 'unixReviewTime': 1423785600, 'sentiment_review': 0.0, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 9, 2015', 'reviewerID': 'AZSP9XAX38DG0', 'asin': '098949232X', 'reviewerName': 'Kristina Edwards', 'reviewText': 'I love all the space facts that this calendar has, one of the best space calendars that I have found.', 'summary': 'I love all the space facts that this calendar has', 'unixReviewTime': 1423440000, 'sentiment_review': 0.8555, 'sentiment_summary': 0.6369}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 7, 2015', 'reviewerID': 'A1N5IO8FW9EE6R', 'asin': '098949232X', 'reviewerName': 'Becky Green', 'reviewText': 'Hung it in a high school class room. Big hit with the students', 'summary': 'Five Stars', 'unixReviewTime': 1423267200, 'sentiment_review': 0.0, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 2, 2015', 'reviewerID': 'A1QI7X0NQ1PUHD', 'asin': '098949232X', 'reviewerName': 'Jason D', 'reviewText': 'This is a must for every astronomy lover it has beautiful pictures and lot of other information too.', 'summary': 'A must for astronomy lovers', 'unixReviewTime': 1422835200, 'sentiment_review': 0.8271, 'sentiment_summary': 0.5267}, {'overall': 5.0, 'verified': True, 'reviewTime': '02 1, 2015', 'reviewerID': 'A3SF5P30FK4Y5Y', 'asin': '098949232X', 'reviewerName': '_pjjs_', 'reviewText': 'Nice printing. Lovely images. Useful information.', 'summary': 'Great & interesting calendar', 'unixReviewTime': 1422748800, 'sentiment_review': 0.8591, 'sentiment_summary': 0.7783}, {'overall': 5.0, 'verified': True, 'reviewTime': '01 27, 2015', 'reviewerID': 'A3KZZYLU5VT4VJ', 'asin': '098949232X', 'reviewerName': 'HighTech', 'reviewText': 'Very nice and delivered in a box which kept the calendar flat and un-creased and new. Nice pictures and detail.', 'summary': 'Nice wall calendar that i will enjoy and is also good for work', 'unixReviewTime': 1422316800, 'sentiment_review': 0.7089, 'sentiment_summary': 0.836}, {'overall': 5.0, 'verified': False, 'reviewTime': '01 27, 2015', 'reviewerID': 'ALK31UO248EH1', 'asin': '098949232X', 'reviewerName': 'Wendy Behrbaum', 'reviewText': 'I have been buying this, and the desk calendar as well, for years. It is beautifully done, filled with interesting facts and easy to use. I would recommend it to anyone.', 'summary': 'It is beautifully done, filled with interesting facts and easy to ...', 'unixReviewTime': 1422316800, 'sentiment_review': 0.9169, 'sentiment_summary': 0.8519}, {'overall': 5.0, 'verified': True, 'reviewTime': '01 23, 2015', 'reviewerID': 'AP5I1RWKMQ6BT', 'asin': '098949232X', 'reviewerName': 'M. J. Bailey', 'reviewText': 'Each page is full of great info. Great addition for space enthusiast.', 'summary': 'Visual eye candy...', 'unixReviewTime': 1421971200, 'sentiment_review': 0.8934, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': True, 'reviewTime': '01 22, 2015', 'reviewerID': 'A1TKWOUJB8OE8T', 'asin': '098949232X', 'reviewerName': 'Mike Stauffer', 'reviewText': 'One of the coolest purchases I\\'ve ever made. I\\'ll absolutely be getting next year\\'s calendar as well. All the extra cool facts and information about everything space-related make every day interesting. There are even \"this day in space history\" tidbits on most squares, moon phase indicators on every day, monthly sky guides for viewing various planets and other interesting celestial bodies, and even coordinates for telescopes. You\\'ll learn something new every day for sure if you have this calendar! 10/10, would absolutely reccomend', 'summary': 'All the extra cool facts and information about everything space-related make every day ...', 'unixReviewTime': 1421884800, 'sentiment_review': 0.8858, 'sentiment_summary': 0.3182}, {'overall': 5.0, 'verified': True, 'reviewTime': '01 22, 2015', 'reviewerID': 'A1VKQUQJHJRA3F', 'asin': '098949232X', 'reviewerName': 'Ian Dorge', 'reviewText': 'Great pictures and useful information.', 'summary': 'Five Stars', 'unixReviewTime': 1421884800, 'sentiment_review': 0.7906, 'sentiment_summary': 0.0}, {'overall': 5.0, 'verified': True, 'reviewTime': '01 20, 2015', 'reviewerID': 'A1399ZMDHQ1YH', 'asin': '098949232X', 'reviewerName': 'Wino', 'reviewText': \"This thing is Big!  It's a bunch of beautiful space photos.  We belong in Space.  Going there is more money than I care to spend, more than I could ever afford, and likely more than I can crowdfund.  This shows your support for space activities.  As always, exploration pays back way more than it costs, and this calendar helps support people who believe in the future as limitless, not a place to hide but a place to rush toward.\\n\\nMaybe the Affordable Space Travel Act will make it free.  Then we can all go there several times a year, right?  I can't wait. But I have to, so for the moment I have a gorgeous calendar on my wall.\\n\\nBuy it.  You won't be disappointed.\", 'summary': 'Not all Who Wander are Lost (Jrr Tolkien).  If you think we belong in space, this is for you.', 'unixReviewTime': 1421712000, 'sentiment_review': 0.9734, 'sentiment_summary': -0.3182}]\n"
     ]
    }
   ],
   "source": [
    "print(new_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write back to file\n",
    "with open('data/Cell_Phones_and_Accessories_Sentiment.json', 'w') as f:\n",
    "    for line in new_data[:20000]:\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split the data using the Spark random splitter provided in utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+\n",
      "|overall|productIndex|reviewerIndex|\n",
      "+-------+------------+-------------+\n",
      "|    1.0|        5748|            1|\n",
      "|    1.0|        9151|            2|\n",
      "|    5.0|         966|            3|\n",
      "|    5.0|       13097|            4|\n",
      "|    5.0|         301|            5|\n",
      "|    4.0|        5010|            6|\n",
      "|    1.0|       11437|            7|\n",
      "|    1.0|        2172|            8|\n",
      "|    5.0|       16822|            9|\n",
      "|    5.0|       14702|           10|\n",
      "|    5.0|        4814|           11|\n",
      "|    2.0|       15869|           12|\n",
      "|    1.0|        5748|           13|\n",
      "|    1.0|       14702|           14|\n",
      "|    5.0|        3756|           15|\n",
      "|    5.0|       13097|           16|\n",
      "|    4.0|        1083|           17|\n",
      "|    2.0|        2246|           18|\n",
      "|    5.0|        2321|           19|\n",
      "|    5.0|        5309|           20|\n",
      "+-------+------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "data = data.select([c for c in data.columns if c in ['productIndex','reviewerIndex','overall', 'reviewText', 'summary']])\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N train 15029\n",
      "N test 4971\n"
     ]
    }
   ],
   "source": [
    "train, test = spark_random_split(data, ratio=0.75, seed=420) #;)\n",
    "print (\"N train\", train.cache().count())\n",
    "print (\"N test\", test.cache().count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train the ALS model on the training data, and get the top-k recommendations for our testing data\n",
    "\n",
    "To predict movie ratings, we use the rating data in the training set as users' explicit feedback. The hyperparameters used in building the model are referenced from [here](http://mymedialite.net/examples/datasets.html). We do not constrain the latent factors (`nonnegative = False`) in order to allow for both positive and negative preferences towards movies.\n",
    "Timing will vary depending on the machine being used to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {\n",
    "    \"itemCol\": \"productIndex\",\n",
    "    \"userCol\": \"reviewerIndex\",\n",
    "    \"ratingCol\": \"overall\",\n",
    "}\n",
    "\n",
    "\n",
    "als = ALS(\n",
    "    rank=10,\n",
    "    maxIter=15,\n",
    "    implicitPrefs=False,\n",
    "    regParam=0.05,\n",
    "    coldStartStrategy='drop',\n",
    "#     nonnegative=TRUE,\n",
    "    seed=42,\n",
    "    #TODO figure out what this does\n",
    "    **header\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 7.106967210769653 seconds for training.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = als.fit(train)\n",
    "train_time = time.time() - start_time\n",
    "print(\"Took {} seconds for training.\".format(train_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the movie recommendation use case, recommending movies that have been rated by the users do not make sense. Therefore, the rated movies are removed from the recommended items.\n",
    "\n",
    "In order to achieve this, we recommend all movies to all users, and then remove the user-movie pairs that exist in the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 61.163707971572876 seconds for prediction.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Get the cross join of all user-item pairs and score them.\n",
    "users = train.select('productIndex').distinct()\n",
    "items = train.select('reviewerIndex').distinct()\n",
    "user_item = users.crossJoin(items)\n",
    "dfs_pred = model.transform(user_item)\n",
    "\n",
    "# Remove seen items.\n",
    "dfs_pred_exclude_train = dfs_pred.alias(\"pred\").join(\n",
    "    train.alias(\"train\"),\n",
    "    (dfs_pred['productIndex'] == train['productIndex']) & (dfs_pred['reviewerIndex'] == train['reviewerIndex']),\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "top_all = dfs_pred_exclude_train.filter(dfs_pred_exclude_train[\"train.overall\"].isNull()) \\\n",
    "    .select('pred.' + 'productIndex', 'pred.' + 'reviewerIndex', 'pred.' + \"prediction\")\n",
    "\n",
    "# In Spark, transformations are lazy evaluation\n",
    "# Use an action to force execute and measure the test time \n",
    "top_all.cache().count()\n",
    "\n",
    "test_time = time.time() - start_time\n",
    "print(\"Took {} seconds for prediction.\".format(test_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------------+-----------+\n",
      "|productIndex|reviewerIndex| prediction|\n",
      "+------------+-------------+-----------+\n",
      "|           1|          587|  -3.286294|\n",
      "|           1|         1208| 0.36795348|\n",
      "|           1|         1348| -3.2554672|\n",
      "|           1|         1677|-0.38888377|\n",
      "|           1|         1702| 0.78687894|\n",
      "|           1|         1720|  0.7981349|\n",
      "|           1|         2086| -1.1226474|\n",
      "|           1|         2324|  -3.286294|\n",
      "|           1|         2483|  -3.905129|\n",
      "|           1|         2667| 0.38557625|\n",
      "|           1|         3452|  -3.286294|\n",
      "|           1|         3468| -1.4968638|\n",
      "|           1|         3668|  -3.286294|\n",
      "|           1|         4136|-0.38994172|\n",
      "|           1|         4949|-0.26167196|\n",
      "|           1|         5501| -1.1960809|\n",
      "|           1|         5562| 0.23899707|\n",
      "|           1|         5668| -0.7484319|\n",
      "|           1|         5957|  -3.905129|\n",
      "|           1|         6031| -0.4864055|\n",
      "+------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_all.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate how well ALS performs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_eval = SparkRankingEvaluation(test, top_all, k = TOP_K, col_user=\"productIndex\", col_item=\"reviewerIndex\", \n",
    "                                    col_rating=\"overall\", col_prediction=\"prediction\", \n",
    "                                    relevancy_method=\"top_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS\n",
      "Top K:\t10\n",
      "MAP:\t0.000375\n",
      "NDCG:\t0.000979\n",
      "Precision@K:\t0.000901\n",
      "Recall@K:\t0.000901\n"
     ]
    }
   ],
   "source": [
    "print(\"Model:\\tALS\",\n",
    "      \"Top K:\\t%d\" % rank_eval.k,\n",
    "      \"MAP:\\t%f\" % rank_eval.map_at_k(),\n",
    "      \"NDCG:\\t%f\" % rank_eval.ndcg_at_k(),\n",
    "      \"Precision@K:\\t%f\" % rank_eval.precision_at_k(),\n",
    "      \"Recall@K:\\t%f\" % rank_eval.recall_at_k(), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Evaluate rating prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+-------------+-----------+\n",
      "|overall|productIndex|reviewerIndex| prediction|\n",
      "+-------+------------+-------------+-----------+\n",
      "|    5.0|       16224|        10377|  4.9629183|\n",
      "|    3.0|       16224|         8061| -2.7615619|\n",
      "|    4.0|        5529|          631|-0.20651442|\n",
      "|    4.0|        5529|        17054| 0.08290452|\n",
      "|    4.0|        5529|         2132|  -1.548662|\n",
      "|    4.0|       14410|        14817| 0.50653875|\n",
      "|    2.0|       14410|         4883| 0.20261544|\n",
      "|    4.0|        8053|         1876|   2.069514|\n",
      "|    3.0|        8053|        10628|-0.63113046|\n",
      "|    1.0|        8053|         5745|  1.9729208|\n",
      "|    3.0|       14370|         7448|  4.1374593|\n",
      "|    4.0|        4227|        11382| -2.1725307|\n",
      "|    4.0|       11437|         6912|  2.0627642|\n",
      "|    2.0|       11437|        10047|  1.3751763|\n",
      "|    4.0|       13988|         2927|   3.784785|\n",
      "|    5.0|        8131|         9362|  1.2370882|\n",
      "|    3.0|       16543|         2142|  3.9550729|\n",
      "|    1.0|       16543|        13528|  0.9887682|\n",
      "|    4.0|       16543|         1259|   2.418448|\n",
      "|    5.0|       16543|         6667|  3.1583385|\n",
      "+-------+------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate predicted ratings.\n",
    "prediction = model.transform(test)\n",
    "prediction.cache().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:\tALS rating prediction\n",
      "RMSE:\t3.371438\n",
      "MAE:\t2.827619\n",
      "Explained variance:\t-1.371053\n",
      "R squared:\t-5.381247\n"
     ]
    }
   ],
   "source": [
    "rating_eval = SparkRatingEvaluation(test, prediction, col_user=\"productIndex\", col_item=\"reviewerIndex\", \n",
    "                                    col_rating=\"overall\", col_prediction=\"prediction\")\n",
    "\n",
    "print(\"Model:\\tALS rating prediction\",\n",
    "      \"RMSE:\\t%f\" % rating_eval.rmse(),\n",
    "      \"MAE:\\t%f\" % rating_eval.mae(),\n",
    "      \"Explained variance:\\t%f\" % rating_eval.exp_var(),\n",
    "      \"R squared:\\t%f\" % rating_eval.rsquared(), sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'papermill' has no attribute 'record'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-890acb23b3be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Record results with papermill for tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpapermill\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ndcg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndcg_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_at_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'papermill' has no attribute 'record'"
     ]
    }
   ],
   "source": [
    "if is_jupyter():\n",
    "    # Record results with papermill for tests\n",
    "    import papermill as pm\n",
    "    pm.record(\"map\", rank_eval.map_at_k())\n",
    "    pm.record(\"ndcg\", rank_eval.ndcg_at_k())\n",
    "    pm.record(\"precision\", rank_eval.precision_at_k())\n",
    "    pm.record(\"recall\", rank_eval.recall_at_k())\n",
    "    pm.record(\"rmse\", rating_eval.rmse())\n",
    "    pm.record(\"mae\", rating_eval.mae())\n",
    "    pm.record(\"exp_var\", rating_eval.exp_var())\n",
    "    pm.record(\"rsquared\", rating_eval.rsquared())\n",
    "    pm.record(\"train_time\", train_time)\n",
    "    pm.record(\"test_time\", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleanup spark instance\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
